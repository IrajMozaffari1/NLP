{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Term Frequency - Inverse Document Frequency (TF-IDF)\n",
        "\n",
        "\n",
        "* TF-IDF is a **statistical** measure.\n",
        "* It reflects how important/relevant a word is to a document in a collection or corpus.\n",
        "*   It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling.\n",
        "*   A [survey conducted in 2015](https://kops.uni-konstanz.de/handle/123456789/32348) showed that 83% of text-based recommender systems in digital libraries use tf–idf.\n",
        "*   The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\n",
        "* Applications: Search Engines (in determining the relevance of queries and documents) and stop-words removal (especially in text-summarization or document classification) \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OByqxxRfPokl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Term Frequency (TF)\n",
        "\n",
        "\n",
        "*   The first form of term weighting is due to Hans Peter Luhn (1957) [link text](https://ieeexplore.ieee.org/document/5392697)\n",
        "*   The number of times a term occurs in a document is called its term frequency\n",
        "\n"
      ],
      "metadata": {
        "id": "JGS2ROQIXbmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inverse Document Frequency\n",
        "\n",
        "\n",
        "*   Motivation: TF will tend to incorrectly emphasize documents which happen to use the words like \"the\" more frequently\n",
        "*   [Karen Spärck Jones](https://en.wikipedia.org/wiki/Karen_Sp%C3%A4rck_Jones) (1972) conceived a statistical interpretation of term-specificity called Inverse Document Frequency (idf), which became a cornerstone of term weighting\n",
        "\n"
      ],
      "metadata": {
        "id": "ypqPjtYcxTli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from scipy.sparse import csr_matrix\n",
        "import math\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np "
      ],
      "metadata": {
        "id": "BFwFM6TITebv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "      'this is the first document',\n",
        "      'this document is the second document',\n",
        "      'and this is the third one',\n",
        "      'is this the first document',\n",
        " ] "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def IDF(corpus, unique_words):\n",
        "   idf_dict={}\n",
        "   N=len(corpus)\n",
        "   for i in unique_words:\n",
        "     count=0\n",
        "     for sen in corpus:\n",
        "       if i in sen.split():\n",
        "         count=count+1\n",
        "       idf_dict[i]=(math.log((1+N)/(count+1)))+1\n",
        "   return idf_dict "
      ],
      "metadata": {
        "id": "0Dq2baGpSYTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(whole_data):\n",
        "    unique_words = set()\n",
        "    if isinstance(whole_data, (list,)):\n",
        "      for x in whole_data:\n",
        "        for y in x.split():\n",
        "          if len(y)<2:\n",
        "            continue\n",
        "          unique_words.add(y)\n",
        "      unique_words = sorted(list(unique_words))\n",
        "      vocab = {j:i for i,j in enumerate(unique_words)}\n",
        "      Idf_values_of_all_unique_words=IDF(whole_data,unique_words)\n",
        "    return vocab, Idf_values_of_all_unique_words\n"
      ],
      "metadata": {
        "id": "LF6z9dvpSaEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vocabulary, idf_of_vocabulary=fit(corpus) "
      ],
      "metadata": {
        "id": "s8X_WuYl3fOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(Vocabulary.keys())) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bjRArb51TF_",
        "outputId": "4439137b-74b8-4435-81c8-df2135d6b418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(dataset, vocabulary, idf_values):\n",
        "     sparse_matrix= csr_matrix( (len(dataset), len(vocabulary)), dtype=np.float64)\n",
        "     for row  in range(0,len(dataset)):\n",
        "       number_of_words_in_sentence=Counter(dataset[row].split())\n",
        "       for word in dataset[row].split():\n",
        "           if word in  list(vocabulary.keys()):\n",
        "               tf_idf_value=(number_of_words_in_sentence[word]/len(dataset[row].split()))*(idf_values[word])\n",
        "               sparse_matrix[row,vocabulary[word]]=tf_idf_value\n",
        "     print(\"NORM FORM\\n\",normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False))\n",
        "     output =normalize(sparse_matrix, norm='l2', axis=1, copy=True, return_norm=False)\n",
        "     return output\n"
      ],
      "metadata": {
        "id": "Dy8KSkm31Z8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output=transform(corpus,Vocabulary,idf_of_vocabulary)\n",
        "print(final_output.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IopUTyh1g6u",
        "outputId": "502ab4d7-56bf-4ce3-c957-74dd450be043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NORM FORM\n",
            "   (0, 1)\t0.4697913855799205\n",
            "  (0, 2)\t0.580285823684436\n",
            "  (0, 3)\t0.3840852409148149\n",
            "  (0, 6)\t0.3840852409148149\n",
            "  (0, 8)\t0.3840852409148149\n",
            "  (1, 1)\t0.6876235979836937\n",
            "  (1, 3)\t0.2810886740337529\n",
            "  (1, 5)\t0.5386476208856762\n",
            "  (1, 6)\t0.2810886740337529\n",
            "  (1, 8)\t0.2810886740337529\n",
            "  (2, 0)\t0.511848512707169\n",
            "  (2, 3)\t0.267103787642168\n",
            "  (2, 4)\t0.511848512707169\n",
            "  (2, 6)\t0.267103787642168\n",
            "  (2, 7)\t0.511848512707169\n",
            "  (2, 8)\t0.267103787642168\n",
            "  (3, 1)\t0.4697913855799205\n",
            "  (3, 2)\t0.580285823684436\n",
            "  (3, 3)\t0.3840852409148149\n",
            "  (3, 6)\t0.3840852409148149\n",
            "  (3, 8)\t0.3840852409148149\n",
            "(4, 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/_index.py:84: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_intXint(row, col, x.flat[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_output[0].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsWQhnPi1ipZ",
        "outputId": "9e0b6740-72bc-41d3-d501-ba3f227a631c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TF/IDF - RezaShokrzad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}