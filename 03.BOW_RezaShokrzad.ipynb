{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Bag Of Words (BOW)\n",
        "\n",
        "\n",
        "\n",
        "*   The bag-of-words (BOW) model is a **representation** for a text.\n",
        "* An early reference to \"bag of words\" in a linguistic context can be found in Zellig Harris's 1954 article on [Distributional Structure](https://www.tandfonline.com/doi/abs/10.1080/00437956.1954.11659520).\n",
        "*   It creates arbitrary text into **fixed-length vectors** by counting how many times each word appears.\n",
        "*   This process is also called **vectorization**.\n",
        "*   The bag-of-words model is commonly used in methods of **document classification** where the (frequency of) occurrence of each word is used as a feature for training a classifier.\n",
        "* The BOW model is one example of a Vector Space Model (VSM).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OByqxxRfPokl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "docs = [\n",
        "  'the cat sat',\n",
        "  'the cat sat in the hat',\n",
        "  'the cat with the hat',\n",
        "]\n",
        "\n",
        "## Step 1: Determine the Vocabulary\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(docs)\n",
        "print(f'Vocabulary: {list(tokenizer.word_index.keys())}')\n",
        "\n",
        "## Step 2: Count\n",
        "vectors = tokenizer.texts_to_matrix(docs, mode='count')\n",
        "print(vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFwFM6TITebv",
        "outputId": "e83b5273-a43b-4f02-80fa-0a30fa80367a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['the', 'cat', 'sat', 'hat', 'in', 'with']\n",
            "[[0. 1. 1. 1. 0. 0. 0.]\n",
            " [0. 2. 1. 1. 1. 1. 0.]\n",
            " [0. 2. 1. 0. 1. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "sentence1 = ['John likes to watch movies. Mary likes movies too.']\n",
        "sentence2 = ['Mary also likes to watch football games.']\n",
        "\n",
        "def print_bow(sentence) -> None:\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentence)\n",
        "    sequences = tokenizer.texts_to_sequences(sentence)\n",
        "    word_index = tokenizer.word_index \n",
        "    bow = {}\n",
        "    for key in word_index:\n",
        "        bow[key] = sequences[0].count(word_index[key])\n",
        "\n",
        "    print(f\"Bag of word sentence 1:\\n{bow}\")\n",
        "    print(f'We found {len(word_index)} unique tokens.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_bow(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dq2baGpSYTb",
        "outputId": "436b9d64-8539-4481-9190-62f4f305af73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of word sentence 1:\n",
            "{'likes': 2, 'movies': 2, 'john': 1, 'to': 1, 'watch': 1, 'mary': 1, 'too': 1}\n",
            "We found 7 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_bow(sentence2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF6z9dvpSaEv",
        "outputId": "4947a160-5091-4ee3-978a-2930facb72f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of word sentence 1:\n",
            "{'mary': 1, 'also': 1, 'likes': 1, 'to': 1, 'watch': 1, 'football': 1, 'games': 1}\n",
            "We found 7 unique tokens.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "BOW - RezaShokrzad",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}